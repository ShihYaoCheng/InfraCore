# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
# https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack

## Manages Prometheus and Alertmanager components
prometheusOperator:
  enabled: true
  logLevel: info

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  ## Alertmanager configuration directives
  ## ref: https://prometheus.io/webtools/alerting/routing-tree-editor/
  ##      https://prometheus.io/docs/alerting/latest/configuration/
  config:
    global:
      resolve_timeout: 6m
    route:
      group_by: ['...']
#      group_by: [app]
      group_wait: 30s
      group_interval: 1m
      repeat_interval: 6h
      receiver: 'slack'
      continue: false
#      routes:
#        - receiver: 'slack'
#          matchers:
#          - app="token"
#        - receiver: 'slack'
#          matchers:
#          - app="user"
#        - receiver: 'slack'
#          matchers:
#          - app="table"
    receivers:
      - name: 'null'
      - name: 'slack'
        slack_configs:
        - channel: ${slackChannel}
          api_url: "https://hooks.slack.com/services/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"
#          text: "Summary: {{ .CommonAnnotations.summary }}\nDescription: {{ .CommonAnnotations.description }}\nUrl: {{ .CommonAnnotations.runbook_url }}"
          text: "{{ range .Alerts }}\nSeverity:{{ .Labels.severity }}\nSummary:{{ .Annotations.summary }}\nDescription:{{ .Annotations.description }}\nUrl:{{ .Annotations.runbook_url }} \n{{ end }}"
    templates:
      - '/etc/alertmanager/config/*.tmpl'

  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    ## Log level for Alertmanager to be configured with.
    ##
    logLevel: info
#    logLevel: debug

    ## Size is the expected size of the alertmanager cluster. The controller will eventually
    ## make the size of the running cluster equal to the expected size.
    replicas: 1

    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
    ##
    storage: {}
    # volumeClaimTemplate:
    #   spec:
    #     storageClassName: gluster
    #     accessModes: ["ReadWriteOnce"]
    #     resources:
    #       requests:
    #         storage: 50Gi
    #   selector: {}

coreDns:
  enabled: false
kubeDns:
  enabled: true
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false

# https://github.com/prometheus-community/helm-charts/issues/423
grafana:
  adminPassword: ${grafanaAdminPassword}
  ingress:
    ## If true, Grafana Ingress will be created
    enabled: false

    ## Annotations for Grafana Ingress
#    annotations:
#      kubernetes.io/ingress.class: traefik
#      traefik.ingress.kubernetes.io/router.entrypoints: web
#      nginx.ingress.kubernetes.io/rewrite-target: /$2

    ## Hostnames.
    ## Must be provided if Ingress is enable.
    # hosts:
    #   - grafana.domain.com
#    hosts:
#      - sre.origingaia.com

    ## Path for grafana ingress
#    path: /grafana(/|$)(.*)
#    path: /grafana/
#    path: /
  grafana.ini:
    server:
      root_url: "https://*.origingaia.com/grafana/"
      serve_from_sub_path: true

  ## Configure grafana dashboard providers
  ## ref: http://docs.grafana.org/administration/provisioning/#dashboards
  ##
  ## `path` must be /var/lib/grafana/dashboards/<provider_name>
  ##
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      # <string> an unique provider name. Required
      - name: 'sre'
        # <int> Org id. Default to 1
        orgId: 1
        # <string> name of the dashboard folder.
        folder: 'SRE'
        # <string> provider type. Default to 'file'
        type: file
        # <bool> disable dashboard deletion
        disableDeletion: true
        # <int> how often Grafana will scan for changed dashboards
        updateIntervalSeconds: 10
        # <bool> allow updating provisioned dashboards from the UI
        allowUiUpdates: false
        options:
          # <string, required> path to dashboard files on disk. Required when using the 'file' type
          path: /var/lib/grafana/dashboards/sre
          # <bool> use folder names from filesystem to create folders in Grafana
          foldersFromFilesStructure: false

  ## Configure grafana dashboard to import
  ## NOTE: To use dashboards you must also enable/configure dashboardProviders
  ## ref: https://grafana.com/dashboards
  ##
  ## dashboards per provider, use provider name as key.
  ##
  dashboards:
    sre:
      # https://grafana.com/grafana/dashboards/10880
      loki-promtail:
        gnetId: 10880
        revision: 1
        datasource: Prometheus
      # https://grafana.com/grafana/dashboards/11454
      k8s-storage-volume:
        gnetId: 11454
        revision: 14
        datasource: Prometheus
      # https://grafana.com/grafana/dashboards/11455
      k8s-storage-volume-namespace:
        gnetId: 11455
        revision: 6
        datasource: Prometheus
      # https://grafana.com/grafana/dashboards/14348
      sloth-slo-detail:
        gnetId: 14348
        revision: 5
        datasource: Prometheus
      # https://grafana.com/grafana/dashboards/14643
      sloth-slo-high-level:
        gnetId: 14643
        revision: 2
        datasource: Prometheus
      # https://grafana.com/grafana/dashboards/15175
      k8s:
        gnetId: 15175
        revision: 1
        datasource: Prometheus

      tempo-operational:
        url: https://raw.githubusercontent.com/grafana/tempo/main/operations/tempo-mixin/yamls/tempo-operational.json
      tempo-reads:
        url: https://raw.githubusercontent.com/grafana/tempo/main/operations/tempo-mixin/yamls/tempo-reads.json
      tempo-resources:
        url: https://raw.githubusercontent.com/grafana/tempo/main/operations/tempo-mixin/yamls/tempo-resources.json
      tempo-writes:
        url: https://raw.githubusercontent.com/grafana/tempo/main/operations/tempo-mixin/yamls/tempo-writes.json

      argocd:
        url: https://raw.githubusercontent.com/argoproj/argo-cd/master/examples/dashboard.json
      cert-manager:
        url: https://raw.githubusercontent.com/monitoring-mixins/website/master/assets/cert-manager/dashboards/cert-manager.json
#         token: ''
    #   local-dashboard-base64:
    #     url: https://example.com/repository/test-b64.json
  #     token: ''
  #     b64content: true

  # The Prometheus add Loki to DataSource automatically.
  ## Configure additional grafana datasources (passed through tpl)
  ## ref: http://docs.grafana.org/administration/provisioning/#datasources
  # https://grafana.com/docs/grafana/latest/administration/provisioning/#example-data-source-config-file
  additionalDataSources:
  # <string, required> name of the datasource. Required
  - name: Loki
    # <string, required> datasource type. Required
    type: loki
    # <string, required> access mode. proxy or direct (Server or Browser in the UI). Required
    access: proxy
    # <string> url
    url: http://loki.loki:3100
    # <bool> enable/disable basic auth
    basicAuth: false
    # <bool> allow users to edit datasources from the UI.
    editable: false
    # <map> fields that will be converted to json and stored in jsonData
    jsonData:
      # Controls whether a client verifies the server’s certificate chain and host name.
      tlsSkipVerify: true
    version: 1
  - name: Tempo
    type: tempo
    access: proxy
    url: http://tempo.tempo:3100
    basicAuth: false
    editable: false
    jsonData:
      tlsSkipVerify: true
    version: 1


# https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
# https://artifacthub.io/packages/helm/prometheus-community/kube-prometheus-stack
## Deploy a Prometheus instance
prometheus:
  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  prometheusSpec:
    # Select all ServiceMonitor and PodMonitor without any label filter.

    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    ##
    serviceMonitorSelectorNilUsesHelmValues: false

    ## If true, a nil or {} value for prometheus.prometheusSpec.podMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the podmonitors created
    ##
    podMonitorSelectorNilUsesHelmValues: false

    ## If true, a nil or {} value for prometheus.prometheusSpec.probeSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the probes created
    ##
#    probeSelectorNilUsesHelmValues: false

    ## Number of replicas of each shard to deploy for a Prometheus deployment.
    ## Number of replicas multiplied by shards is the total number of Pods created.
    replicas: 1

    ## How long to retain metrics
    retention: 90d

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
    ##
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: ${prometheusStorageClassName}
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: ${prometheusStorageSize}


